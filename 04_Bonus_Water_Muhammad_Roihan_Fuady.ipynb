{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task Bonus"
      ],
      "metadata": {
        "id": "RWxl1Cb6VXgg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZShyAe9FUlOv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_data(batch_size=10):\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "seQh1pcwWJEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_mnist_data(batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OCLC_mOWzSq",
        "outputId": "c265c3fd-35a1-4d91-c7df-84446a5b6bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 292077075.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 73683512.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 156926128.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 6806191.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Compare 3 different configurations while your model is wider/deeper. Show and explain the performance result."
      ],
      "metadata": {
        "id": "8GCPGIAWbm6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def train(model, train_loader, criterion, optimizer, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images.view(-1, 28 * 28))\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        average_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {average_loss:.4f}')"
      ],
      "metadata": {
        "id": "ai0Lyvi-V3Fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images.view(-1, 28 * 28))\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_labels.extend(labels.numpy())\n",
        "            all_preds.extend(preds.numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "l0eT0hLmWb_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WideModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WideModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "wide_model = WideModel()\n",
        "optimizer = optim.SGD(wide_model.parameters(), lr=0.01, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 10\n",
        "train(wide_model, train_loader, criterion, optimizer, num_epochs)\n",
        "accuracy1 = evaluate_model(wide_model, test_loader)\n",
        "print(f'Accuracy (Wide Model): {accuracy1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxVKtBwWVjvN",
        "outputId": "cc7ce554-d953-450b-a3c1-46ec453eab4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.3617\n",
            "Epoch [2/10] Loss: 0.2043\n",
            "Epoch [3/10] Loss: 0.1704\n",
            "Epoch [4/10] Loss: 0.1539\n",
            "Epoch [5/10] Loss: 0.1425\n",
            "Epoch [6/10] Loss: 0.1229\n",
            "Epoch [7/10] Loss: 0.1226\n",
            "Epoch [8/10] Loss: 0.1127\n",
            "Epoch [9/10] Loss: 0.1057\n",
            "Epoch [10/10] Loss: 0.0997\n",
            "Accuracy (Wide Model): 0.9617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeepModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 128)\n",
        "        self.fc4 = nn.Linear(128, 128)\n",
        "        self.fc5 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n",
        "deep_model = DeepModel()\n",
        "optimizer = optim.SGD(deep_model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(deep_model, train_loader, criterion, optimizer, num_epochs)\n",
        "accuracy2 = evaluate_model(deep_model, test_loader)\n",
        "print(f'Accuracy (Deep Model): {accuracy2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjkuxdU0VoBv",
        "outputId": "3def5a63-fbc1-4a58-ffa2-251541e2952d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.4470\n",
            "Epoch [2/10] Loss: 0.2198\n",
            "Epoch [3/10] Loss: 0.1736\n",
            "Epoch [4/10] Loss: 0.1512\n",
            "Epoch [5/10] Loss: 0.1318\n",
            "Epoch [6/10] Loss: 0.1202\n",
            "Epoch [7/10] Loss: 0.1163\n",
            "Epoch [8/10] Loss: 0.1070\n",
            "Epoch [9/10] Loss: 0.0968\n",
            "Epoch [10/10] Loss: 0.0976\n",
            "Accuracy (Deep Model): 0.9635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OriginalModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OriginalModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "original_model = OriginalModel()\n",
        "optimizer = optim.SGD(original_model.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(original_model, train_loader, criterion, optimizer, num_epochs)\n",
        "accuracy3 = evaluate_model(original_model, test_loader)\n",
        "print(f'Accuracy (Original Model): {accuracy3:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3M2CeGvVrUn",
        "outputId": "c3b77329-0bd5-4ac9-ecb7-97a5912bab80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.4165\n",
            "Epoch [2/10] Loss: 0.2661\n",
            "Epoch [3/10] Loss: 0.2314\n",
            "Epoch [4/10] Loss: 0.2027\n",
            "Epoch [5/10] Loss: 0.1887\n",
            "Epoch [6/10] Loss: 0.1726\n",
            "Epoch [7/10] Loss: 0.1641\n",
            "Epoch [8/10] Loss: 0.1551\n",
            "Epoch [9/10] Loss: 0.1522\n",
            "Epoch [10/10] Loss: 0.1464\n",
            "Accuracy (Original Model): 0.9475\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil perhitungan untuk mendapatkan nilai akurasi dari 3 model tersebut, yaitu:\n",
        "\n",
        "1. WideModel = Accuracy (Wide Model): 0.9617\n",
        "2. DeepModel = Accuracy (Deep Model): 0.9635\n",
        "3. OriginalModel = Accuracy (Original Model): 0.9475\n",
        "\n",
        "Maka, dapat disimpulkan bahwa akurasi performa dari ketiga model di atas. Model yang memiliki akurasi tertinggi pada data uji adalah DeepModel = Accuracy (Deep Model): 0.9635 merupakan model pilihan terbaik."
      ],
      "metadata": {
        "id": "ayKnhNLAqlF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Compare 3 configurations for different Loss Function. Show and explain your performance result"
      ],
      "metadata": {
        "id": "Ce_4uefbbwEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_mnist_data(batch_size=10)"
      ],
      "metadata": {
        "id": "a2IeVjiZcbHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "eUNjqQW8c7M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = NeuralNetwork()\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(model1, train_loader, criterion1, optimizer, num_epochs)\n",
        "accuracy1 = evaluate_model(model1, test_loader)\n",
        "print(f'Accuracy (CrossEntropyLoss): {accuracy1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9266DU8Yb1dF",
        "outputId": "5e9fda9f-eaa0-4325-ec8b-da2a8922991a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 0.4087\n",
            "Epoch [2/10] Loss: 0.2625\n",
            "Epoch [3/10] Loss: 0.2230\n",
            "Epoch [4/10] Loss: 0.2056\n",
            "Epoch [5/10] Loss: 0.1842\n",
            "Epoch [6/10] Loss: 0.1717\n",
            "Epoch [7/10] Loss: 0.1619\n",
            "Epoch [8/10] Loss: 0.1578\n",
            "Epoch [9/10] Loss: 0.1562\n",
            "Epoch [10/10] Loss: 0.1467\n",
            "Accuracy (CrossEntropyLoss): 0.9545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = NeuralNetwork()\n",
        "criterion2 = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(model2, train_loader, criterion2, optimizer, num_epochs)\n",
        "accuracy2 = evaluate_model(model2, test_loader)\n",
        "print(f'Accuracy (NLLLoss): {accuracy2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfNMRIA1dB_X",
        "outputId": "96bdc2fb-bafa-4df1-b1b2-b054fa36e2dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: nan\n",
            "Epoch [2/10] Loss: nan\n",
            "Epoch [3/10] Loss: nan\n",
            "Epoch [4/10] Loss: nan\n",
            "Epoch [5/10] Loss: nan\n",
            "Epoch [6/10] Loss: nan\n",
            "Epoch [7/10] Loss: nan\n",
            "Epoch [8/10] Loss: nan\n",
            "Epoch [9/10] Loss: nan\n",
            "Epoch [10/10] Loss: nan\n",
            "Accuracy (NLLLoss): 0.0980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = NeuralNetwork()\n",
        "criterion3 = nn.MSELoss()\n",
        "optimizer = optim.SGD(model3.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "        model3.train()\n",
        "        running_loss = 0.0\n",
        "        for data in train_loader:\n",
        "            x, y = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model3(x.view(-1, 28*28))\n",
        "\n",
        "            # Konversi label target menjadi Float\n",
        "            y = y.float()\n",
        "\n",
        "            loss = criterion3(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        average_loss = running_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}] Loss: {average_loss:.4f}')\n",
        "\n",
        "accuracy3 = evaluate_model(model3, test_loader)\n",
        "print(f'Accuracy (MSELoss): {accuracy3:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR8AX4AtdOH5",
        "outputId": "a0a48bd2-af20-480a-8b74-e95ac46b947b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Loss: 8.5634\n",
            "Epoch [2/10] Loss: 8.4311\n",
            "Epoch [3/10] Loss: 8.4317\n",
            "Epoch [4/10] Loss: 8.4295\n",
            "Epoch [5/10] Loss: 8.4325\n",
            "Epoch [6/10] Loss: 8.4304\n",
            "Epoch [7/10] Loss: 8.4362\n",
            "Epoch [8/10] Loss: 8.4336\n",
            "Epoch [9/10] Loss: 8.4296\n",
            "Epoch [10/10] Loss: 8.4290\n",
            "Accuracy (MSELoss): 0.1028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil perhitungan untuk mendapatkan nilai akurasi dari 3 model tersebut, yaitu:\n",
        "\n",
        "1. CrossEntropyLoss = Accuracy (CrossEntropyLoss): 0.9545\n",
        "2. NLLLoss = Accuracy (NLLLoss): 0.0980\n",
        "3. MSELoss = Accuracy (MSELoss): 0.1028\n",
        "\n",
        "Maka, dapat disimpulkan bahwa akurasi performa dari ketiga model di atas. Model yang memiliki akurasi tertinggi pada data uji adalah CrossEntropyLoss = Accuracy (CrossEntropyLoss): 0.9545 merupakan model pilihan terbaik."
      ],
      "metadata": {
        "id": "5n3IAcPTseI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Compare 3 configurations for the activation function. Show and explain your performance result"
      ],
      "metadata": {
        "id": "oieeul0rnBuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = load_mnist_data(batch_size=10)"
      ],
      "metadata": {
        "id": "rY-4wnLTnIRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLUModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ReLUModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "model1 = ReLUModel()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(model1, train_loader, criterion1, optimizer, num_epochs)\n",
        "accuracy1 = evaluate_model(model1, test_loader)\n",
        "print(f'Accuracy (ReLU): {accuracy1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB_mB7gfnTXx",
        "outputId": "b0eeb20e-f9bc-4db6-b554-be64696fc48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.41878489256236207\n",
            "Epoch 2, Loss: 0.27148670624190585\n",
            "Epoch 3, Loss: 0.23239608119466568\n",
            "Epoch 4, Loss: 0.2095702025466256\n",
            "Epoch 5, Loss: 0.1935319307468347\n",
            "Epoch 6, Loss: 0.18925841233344445\n",
            "Epoch 7, Loss: 0.1826826002076441\n",
            "Epoch 8, Loss: 0.17547760468849075\n",
            "Epoch 9, Loss: 0.16851109756781033\n",
            "Epoch 10, Loss: 0.16587752328297634\n",
            "Accuracy (ReLU): 0.9514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SigmoidModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SigmoidModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "model2 = SigmoidModel()\n",
        "optimizer = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(model2, train_loader, criterion1, optimizer, num_epochs)\n",
        "accuracy2 = evaluate_model(model2, test_loader)\n",
        "print(f'Accuracy (Sigmoid): {accuracy2:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_9NlaCDnhea",
        "outputId": "e329b8bc-81be-467e-9351-8c9cd57a3f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.34865920633248365\n",
            "Epoch 2, Loss: 0.17011614429527738\n",
            "Epoch 3, Loss: 0.12446483051976732\n",
            "Epoch 4, Loss: 0.09867595609852772\n",
            "Epoch 5, Loss: 0.08204613654753\n",
            "Epoch 6, Loss: 0.07015426817190504\n",
            "Epoch 7, Loss: 0.06125538524226916\n",
            "Epoch 8, Loss: 0.05438644877596865\n",
            "Epoch 9, Loss: 0.048017448095786675\n",
            "Epoch 10, Loss: 0.042742325718501284\n",
            "Accuracy (Sigmoid): 0.9774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TanhModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TanhModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "model3 = TanhModel()\n",
        "optimizer = optim.SGD(model3.parameters(), lr=0.01, momentum=0.9)\n",
        "num_epochs = 10\n",
        "train(model3, train_loader, criterion1, optimizer, num_epochs)\n",
        "accuracy3 = evaluate_model(model3, test_loader)\n",
        "print(f'Accuracy (Tanh): {accuracy3:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJuyUxq7ntRj",
        "outputId": "e6ed878d-26e7-4e8b-ce66-2b2449878c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4296437833693344\n",
            "Epoch 2, Loss: 0.4044272551409279\n",
            "Epoch 3, Loss: 0.3928960522466805\n",
            "Epoch 4, Loss: 0.3826399141418127\n",
            "Epoch 5, Loss: 0.3670486559078951\n",
            "Epoch 6, Loss: 0.33130472946110723\n",
            "Epoch 7, Loss: 0.31381327990776237\n",
            "Epoch 8, Loss: 0.3159878531287347\n",
            "Epoch 9, Loss: 0.2965952137750962\n",
            "Epoch 10, Loss: 0.28008833530296884\n",
            "Accuracy (Tanh): 0.9266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berdasarkan hasil perhitungan untuk mendapatkan nilai akurasi dari 3 model tersebut, yaitu:\n",
        "\n",
        "1. ReLU = Accuracy (ReLU): 0.9514\n",
        "2. Sigmoid = Accuracy (Sigmoid): 0.9774\n",
        "3. Tanh = Accuracy (Tanh): 0.9266\n",
        "\n",
        "Maka, dapat disimpulkan bahwa akurasi performa dari ketiga model di atas. Model yang memiliki akurasi tertinggi pada data uji adalah Sigmoid = Accuracy (Sigmoid): 0.9774 merupakan model pilihan terbaik."
      ],
      "metadata": {
        "id": "bR2GL4EmtbOU"
      }
    }
  ]
}